{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dfd7e0c",
   "metadata": {},
   "source": [
    "Essa é a transição crucial de um modelo de **classificação** (que funciona em caracteres isolados) para um sistema de **Reconhecimento Óptico de Caracteres (OCR)** que funciona em imagens complexas.\n",
    "\n",
    "O modelo CNN (`char_recognition_cnn.keras`) é um **classificador de caracteres isolados** ($64 \\times 64$ pixels). Para usá-lo em uma \"imagem qualquer com vários caracteres\", é preciso uma etapa anterior chamada **Segmentação de Caracteres**.\n",
    "\n",
    "O processo completo envolve três etapas principais:\n",
    "\n",
    "## 1\\. Pré-processamento e Limiarização\n",
    "\n",
    "Primeiro, você deve preparar a imagem de entrada para que os caracteres se destaquem do fundo.\n",
    "\n",
    "  * **Carregar a Imagem:** Carregue a imagem complexa original (ex: colorida ou em tons de cinza).\n",
    "  * **Limiarização (Thresholding):** Use técnicas como **limiarização binária** (ex: Otsu's method, usando `cv2.threshold` com OpenCV) para converter a imagem em preto e branco. O objetivo é transformar a imagem em um mapa onde os caracteres são brancos e o fundo é preto, isolando o texto.\n",
    "\n",
    "## 2\\. Segmentação de Caracteres\n",
    "\n",
    "Esta é a etapa mais crítica. Você precisa identificar e recortar cada caractere individualmente.\n",
    "\n",
    "  * **Detecção de Contornos (Contours):** Use bibliotecas como **OpenCV** (`cv2.findContours`) para encontrar todos os contornos (regiões fechadas) na imagem binária. Cada contorno potencialmente representa um caractere.\n",
    "  * **Filtragem:** Filtre os contornos. Descarte aqueles que são muito pequenos (ruído) ou muito grandes (blocos de texto inteiros ou grandes objetos), deixando apenas os que têm a forma e o tamanho típicos de um caractere.\n",
    "  * **Recorte e Padronização:** Para cada contorno filtrado:\n",
    "      * Recorte a região do caractere original (usando a caixa delimitadora do contorno).\n",
    "      * **Redimensione** o caractere recortado para o tamanho de entrada do seu modelo: **$64 \\times 64$ pixels** (e em tons de cinza) – exatamente como você treinou.\n",
    "\n",
    "## 3\\. Classificação com o Modelo CNN\n",
    "\n",
    "Com cada caractere isolado e redimensionado para $64 \\times 64$, você pode alimentar o modelo.\n",
    "\n",
    "  * **Normalização:** Normalize o *array* da imagem recortada ($64 \\times 64 \\times 1$) dividindo os valores por $255$.\n",
    "  * **Previsão:** Passe o *array* normalizado para o seu modelo: `model.predict(caractere_processado)`.\n",
    "  * **Decodificação:** A saída será um vetor de 62 probabilidades ($\\text{Softmax}$). O índice com a maior probabilidade corresponde à previsão do caractere (ex: 'A', '7', 'c').\n",
    "\n",
    "## Desafios\n",
    "\n",
    "O desafio desse método é que ele não lida bem com caracteres em diferentes linhas, fundos muito ruidosos ou fontes muito pequenas/grandes. Para sistemas profissionais, modelos de **Detecção de Objetos** (como YOLO ou SSD, treinados para detectar a **caixa delimitadora** de cada caractere) seriam usados em vez da segmentação por contornos."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
