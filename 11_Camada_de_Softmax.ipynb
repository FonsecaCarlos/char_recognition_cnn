{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c437036b",
   "metadata": {},
   "source": [
    "## Camada de Ativação Softmax em Detalhe\n",
    "\n",
    "A função **Softmax** é uma **função de ativação** usada exclusivamente na **camada de saída** (a última camada $\\text{DENSE}$) de uma rede neural quando o problema é de **classificação multiclasse**, como a classificação dos 62 caracteres do seu projeto Chars74K.\n",
    "\n",
    "Sua principal função é transformar os *scores* brutos e não normalizados (também chamados de *logits*) da camada $\\text{DENSE}$ final em uma **distribuição de probabilidade**.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. A Função Matemática\n",
    "\n",
    "A $\\text{Softmax}$ recebe um vetor de números reais $z$ (os *logits*) e os transforma em um vetor de probabilidades $P$.\n",
    "\n",
    "Para um elemento $i$ do vetor de saída $P$, a fórmula é:\n",
    "\n",
    "$$P_i = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}$$\n",
    "\n",
    "Onde:\n",
    "* $P_i$: A probabilidade prevista para a classe $i$.\n",
    "* $e^{z_i}$: O número $e$ (base do logaritmo natural, $\\approx 2.718$) elevado ao *logit* ($z_i$) da classe $i$.\n",
    "* $\\sum_{j=1}^{K} e^{z_j}$: A soma das exponenciais de *todos* os *logits* de $j=1$ até $K$ (o número total de classes, que no seu caso é 62).\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Propriedades Essenciais\n",
    "\n",
    "O uso da $\\text{Softmax}$ garante duas propriedades cruciais para a classificação:\n",
    "\n",
    "1.  **Soma Igual a Um:** A soma de todos os valores de saída ($P_i$) é sempre exatamente 1. Isso permite que a saída seja interpretada como uma verdadeira distribuição de probabilidade.\n",
    "    $$\\sum_{i=1}^{K} P_i = 1$$\n",
    "\n",
    "2.  **Ênfase no Maior Score:** A função exponencial ($e^x$) na fórmula amplifica as diferenças entre os *logits* de entrada. Scores maiores (mais positivos) se traduzem em probabilidades muito mais altas, enquanto scores menores são esmagados para valores próximos de zero.\n",
    "\n",
    "### Exemplo Ilustrativo\n",
    "\n",
    "Imagine que a última camada $\\text{DENSE}$ produziu os seguintes *scores* brutos (*logits*) para três classes de caracteres:\n",
    "\n",
    "| Classe | Logit ($z$) | $e^z$ | Probabilidade ($\\text{Softmax}$) |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| **'A'** | 2.0 | 7.39 | **82.3%** |\n",
    "| **'B'** | 0.5 | 1.65 | 18.4% |\n",
    "| **'C'** | -1.0 | 0.37 | 4.1% |\n",
    "| **Soma** | 1.5 | 9.41 | **100.0%** |\n",
    "\n",
    "Neste exemplo, mesmo que o *logit* de 'A' (2.0) não seja muito maior que o de 'B' (0.5), a $\\text{Softmax}$ amplifica essa diferença, resultando em uma probabilidade de $82.3\\%$ para 'A'. O modelo decide que a imagem pertence à classe **'A'**."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
