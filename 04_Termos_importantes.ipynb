{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71406df5",
   "metadata": {},
   "source": [
    "Esses termos representam as **camadas fundamentais** que comp√µem a arquitetura de uma Rede Neural Convolucional (CNN), especialmente usadas em tarefas de Vis√£o Computacional.\n",
    "\n",
    "Aqui est√° o significado de cada um:\n",
    "\n",
    "---\n",
    "\n",
    "## üß± Camadas Fundamentais da CNN\n",
    "\n",
    "### 1. CONV (Convolutional Layer - Camada Convolucional)\n",
    "\n",
    "* **Fun√ß√£o:** √â o **n√∫cleo** da CNN. Esta camada aplica um conjunto de **filtros (ou kernels)** √† imagem de entrada para extrair caracter√≠sticas (features) relevantes, como bordas, texturas e cantos.\n",
    "* **Processo:** O filtro \"desliza\" pela imagem (*sliding window*) e realiza a multiplica√ß√£o ponto a ponto e soma dos valores, gerando um **mapa de caracter√≠sticas** (*feature map*). Quanto mais profunda a rede, mais complexas s√£o as caracter√≠sticas extra√≠das.\n",
    "\n",
    "### 2. RELU (Rectified Linear Unit - Unidade Linear Retificada)\n",
    "\n",
    "* **Fun√ß√£o:** √â uma **fun√ß√£o de ativa√ß√£o** aplicada logo ap√≥s cada camada `CONV`. Sua principal tarefa √© introduzir a **n√£o-linearidade** na rede.\n",
    "* **Processo:** Simplesmente transforma todos os valores negativos no mapa de caracter√≠sticas em zero e mant√©m os valores positivos.\n",
    "$$f(x) = \\max(0, x)$$\n",
    "* **Import√¢ncia:** Sem a n√£o-linearidade, a rede seria apenas uma s√©rie de opera√ß√µes lineares, incapaz de aprender padr√µes complexos.\n",
    "\n",
    "### 3. POOL (Pooling Layer - Camada de Agrupamento)\n",
    "\n",
    "* **Fun√ß√£o:** Reduz a dimensionalidade (tamanho espacial) dos mapas de caracter√≠sticas. Isso diminui o n√∫mero de par√¢metros, **reduz o tempo de computa√ß√£o** e ajuda a tornar as caracter√≠sticas detectadas mais robustas a pequenas varia√ß√µes (transla√ß√µes) na imagem.\n",
    "* **Tipo Mais Comum (MaxPool):** A `MaxPooling` seleciona o valor **m√°ximo** de uma pequena janela (ex: $2 \\times 2$) dentro do mapa de caracter√≠sticas e descarta os outros valores.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Camadas Finais (Classifica√ß√£o)\n",
    "\n",
    "As camadas abaixo v√™m geralmente ap√≥s uma sequ√™ncia de `CONV` $\\to$ `RELU` $\\to$ `POOL`.\n",
    "\n",
    "### 4. FLATTEN (Achatamento)\n",
    "\n",
    "* **Fun√ß√£o:** Transforma o formato de sa√≠da das √∫ltimas camadas `CONV` e `POOL` (que s√£o tensoriais 3D: altura $\\times$ largura $\\times$ profundidade) em um **vetor 1D** longo.\n",
    "* **Processo:** Essa camada prepara os dados para serem alimentados nas camadas totalmente conectadas (`DENSE`) subsequentes, que esperam dados em formato de vetor.\n",
    "\n",
    "\n",
    "### 5. DROPOUT (Abandono)\n",
    "\n",
    "O Dropout (abandono, em tradu√ß√£o livre) √© uma t√©cnica de regulariza√ß√£o fundamental em Redes Neurais, especialmente em CNNs, usada para prevenir o overfitting (sobreajuste).\n",
    "Quando um modelo √© treinado demais, ele pode come√ßar a memorizar os dados de treinamento, incluindo o ru√≠do, perde\n",
    "\n",
    "### 6. DENSE (Fully Connected Layer - Camada Totalmente Conectada)\n",
    "\n",
    "* **Fun√ß√£o:** √â uma **Rede Neural Perceptron** tradicional. Cada neur√¥nio nesta camada est√° conectado a todos os neur√¥nios da camada anterior.\n",
    "* **Processo:** Esta camada realiza a **classifica√ß√£o final**. Ela pega as caracter√≠sticas de alto n√≠vel extra√≠das pelas camadas `CONV` e aprende a combina√ß√£o dessas caracter√≠sticas para fazer as previs√µes.\n",
    "\n",
    "### 7. SOFTMAX\n",
    "\n",
    "* **Fun√ß√£o:** √â uma **fun√ß√£o de ativa√ß√£o** aplicada √† **camada de sa√≠da** (`DENSE`) em problemas de classifica√ß√£o multi-classe (como o seu, com 62 classes de caracteres).\n",
    "* **Processo:** Transforma os valores de sa√≠da da √∫ltima camada `DENSE` em um vetor de probabilidades. A soma de todas as probabilidades de sa√≠da √© sempre igual a 1.\n",
    "* **Resultado:** O valor mais alto no vetor final corresponde √† classe que o modelo prev√™ ser a correta. Por exemplo, se a sa√≠da para a classe 'A' for 0.98, o modelo est√° 98% confiante de que a imagem √© a letra 'A'."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
