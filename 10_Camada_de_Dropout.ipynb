{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa9a688e",
   "metadata": {},
   "source": [
    "\n",
    "## Camada Dropout em Detalhe\n",
    "\n",
    "O **Dropout** (abandono, em tradução livre) é uma técnica de **regularização** fundamental em Redes Neurais, especialmente em CNNs, usada para **prevenir o *overfitting*** (sobreajuste).\n",
    "\n",
    "Quando um modelo é treinado demais, ele pode começar a memorizar os dados de treinamento, incluindo o ruído, perdendo a capacidade de generalizar para novos dados (validação ou teste). O Dropout resolve isso.\n",
    "\n",
    "-----\n",
    "\n",
    "## Como o Dropout Funciona\n",
    "\n",
    "O Dropout atua de forma simples, mas poderosa, durante a fase de **treinamento**:\n",
    "\n",
    "1.  **Abandono Aleatório:** Em cada etapa do treinamento (*batch*), uma porcentagem de neurônios (tipicamente entre $20\\%$ e $50\\%$) é **aleatoriamente desativada** (seu valor de saída é definido como zero).\n",
    "2.  **Rede Diferente:** Isso significa que a cada iteração, a rede neural que está aprendendo é ligeiramente diferente, pois alguns neurônios estão \"ausentes\".\n",
    "3.  **Co-Adaptação Prevenida:** Isso impede que qualquer neurônio se torne excessivamente dependente de outro neurônio específico (fenômeno chamado de co-adaptação). Cada neurônio é forçado a aprender recursos mais robustos e independentes, que podem ser usados em combinação com qualquer subconjunto de outros neurônios.\n",
    "\n",
    "**Analogia:** Pense nisso como treinar múltiplas sub-redes menores e diferentes em paralelo. No final, a rede completa se comporta como um \"comitê de especialistas\", onde o conhecimento é distribuído e não concentrado em poucos membros.\n",
    "\n",
    "## Onde e Quando Usar\n",
    "\n",
    "  * **Localização:** Geralmente, o Dropout é aplicado nas **camadas densas (`DENSE`)** da CNN, que vêm após as camadas convolucionais (`CONV`) e de *flattening* (`FLATTEN`). No entanto, pode ser aplicado após camadas convolucionais também.\n",
    "  * **Apenas no Treinamento:** A chave do Dropout é que ele é **desligado** durante a fase de **validação** e **teste**. Nesses momentos, a rede usa todos os seus neurônios, mas os pesos dos neurônios ativos são escalados para compensar a ausência de seus vizinhos durante o treinamento.\n",
    "\n",
    "No código que você viu, a linha:\n",
    "\n",
    "```python\n",
    "Dropout(0.5) \n",
    "```\n",
    "\n",
    "significa que **$50\\%$ dos neurônios** da camada anterior serão desativados aleatoriamente em cada etapa do treinamento."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
