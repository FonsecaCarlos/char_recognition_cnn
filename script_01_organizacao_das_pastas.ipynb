{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f167997e",
   "metadata": {},
   "source": [
    "# O conjunto de dados utilizados para criação desse modelo foi o Chars74k\n",
    "\n",
    "Download:\n",
    "- https://info-ee.surrey.ac.uk/CVSSP/demos/chars74k/EnglishFnt.tgz\n",
    "- https://info-ee.surrey.ac.uk/CVSSP/demos/chars74k/EnglishImg.tgz\n",
    "\n",
    "O script abaixo utiliza as bibliotecas padrão do Python (os, shutil) para manipulação de arquivos e a scikit-learn (sklearn) para realizar a crucial separação estratificada dos dados (80% Treinamento, 10% Validação, 10% Teste).\n",
    "\n",
    "Pré-requisitos: ter as bibliotecas numpy e scikit-learn instaladas:\n",
    "- pip install numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e78e44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removendo diretório existente: /home/carlos/classificacao_segmentacao/chars74k_dataset_final\n",
      "Coletando imagens de: /home/carlos/classificacao_segmentacao/EnglishFnt/English/Fnt\n",
      "Coletando imagens de: /home/carlos/classificacao_segmentacao/EnglishImg/English/Img/GoodImg/Bmp\n",
      "Coletando imagens de: /home/carlos/classificacao_segmentacao/EnglishImg/English/Img/BadImag/Bmp\n",
      "\n",
      "TOTAL de imagens coletadas: 75495\n",
      "\n",
      "--- RESUMO DA DIVISÃO ESTRATIFICADA ---\n",
      "Treinamento: 60396 imagens (80.0%)\n",
      "Validação: 7549 imagens (10.0%)\n",
      "Teste: 7550 imagens (10.0%)\n",
      "---------------------------------------\n",
      "\n",
      "Copiando 60396 imagens para o conjunto de train...\n",
      "\n",
      "Copiando 7549 imagens para o conjunto de validation...\n",
      "\n",
      "Copiando 7550 imagens para o conjunto de test...\n",
      "\n",
      "✅ Organização concluída! O dataset final está em 'chars74k_dataset_final'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. CONFIGURAÇÃO DE DIRETÓRIOS ---\n",
    "# Diretório onde as pastas EnglishFnt e EnglisgImg estão localizadas\n",
    "BASE_DIR = os.getcwd() \n",
    "\n",
    "# Diretório final de saída\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, 'chars74k_dataset_final') \n",
    "\n",
    "# Diretórios de origem do dataset Chars74K\n",
    "FNT_DIR = os.path.join(BASE_DIR, 'EnglishFnt', 'English', 'Fnt')\n",
    "IMG_DIR = os.path.join(BASE_DIR, 'EnglishImg', 'English', 'Img') \n",
    "\n",
    "# Proporções de divisão (Treino/Validação/Teste)\n",
    "TRAIN_RATIO = 0.8\n",
    "VAL_RATIO = 0.1\n",
    "TEST_RATIO = 0.1\n",
    "\n",
    "# --- 2. MAPEAR NOMES DE PASTAS 'SampleXXX' PARA RÓTULOS REAIS ---\n",
    "# O Chars74K usa Sample001-010 para dígitos (0-9), Sample011-036 para maiúsculas (A-Z)\n",
    "# e Sample037-062 para minúsculas (a-z).\n",
    "def get_label_map():\n",
    "    label_map = {}\n",
    "    \n",
    "    # Dígitos (0-9)\n",
    "    for i in range(1, 11):\n",
    "        label_map[f'Sample{i:03d}'] = str(i - 1)\n",
    "\n",
    "    # Letras Maiúsculas (A-Z)\n",
    "    for i in range(11, 37):\n",
    "        char = chr(ord('A') + i - 11)\n",
    "        label_map[f'Sample{i:03d}'] = char\n",
    "\n",
    "    # Letras Minúsculas (a-z)\n",
    "    for i in range(37, 63):\n",
    "        char = chr(ord('a') + i - 37)\n",
    "        label_map[f'Sample{i:03d}'] = char\n",
    "        \n",
    "    return label_map\n",
    "\n",
    "# --- 3. FUNÇÃO PRINCIPAL DE COLETA DE IMAGENS ---\n",
    "def collect_all_images(base_path, label_map):\n",
    "    all_files = []\n",
    "    all_labels = []\n",
    "    \n",
    "    print(f\"Coletando imagens de: {base_path}\")\n",
    "    \n",
    "    # Iterar sobre todas as subpastas SampleXXX\n",
    "    for sample_dir_name in os.listdir(base_path):\n",
    "        if not sample_dir_name.startswith('Sample'):\n",
    "            continue\n",
    "            \n",
    "        sample_path = os.path.join(base_path, sample_dir_name)\n",
    "        if not os.path.isdir(sample_path):\n",
    "            continue\n",
    "            \n",
    "        # Obter o rótulo real (ex: '0', 'A', 'a')\n",
    "        label = label_map.get(sample_dir_name)\n",
    "        if not label:\n",
    "            print(f\"Aviso: Sample ID {sample_dir_name} não encontrado no mapeamento.\")\n",
    "            continue\n",
    "            \n",
    "        # Coletar todos os arquivos .png ou .bmp dentro do diretório SampleXXX\n",
    "        for filename in os.listdir(sample_path):\n",
    "            if filename.endswith(('.png', '.bmp')):\n",
    "                file_path = os.path.join(sample_path, filename)\n",
    "                all_files.append(file_path)\n",
    "                all_labels.append(label)\n",
    "                \n",
    "    return all_files, all_labels\n",
    "\n",
    "# --- 4. FUNÇÃO PARA CRIAR E COPIAR OS ARQUIVOS ---\n",
    "def create_and_copy(file_list, label_list, set_name):\n",
    "    print(f\"\\nCopiando {len(file_list)} imagens para o conjunto de {set_name}...\")\n",
    "    \n",
    "    # Criar a pasta raiz do conjunto (train, validation, ou test)\n",
    "    set_dir = os.path.join(OUTPUT_DIR, set_name)\n",
    "    os.makedirs(set_dir, exist_ok=True)\n",
    "    \n",
    "    for file_path, label in zip(file_list, label_list):\n",
    "        # 1. Criar a subpasta da classe dentro do conjunto (ex: train/A)\n",
    "        target_class_dir = os.path.join(set_dir, label)\n",
    "        os.makedirs(target_class_dir, exist_ok=True)\n",
    "        \n",
    "        # 2. Copiar o arquivo\n",
    "        shutil.copy(file_path, target_class_dir)\n",
    "\n",
    "# --- EXECUÇÃO PRINCIPAL ---\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Limpeza e criação do diretório de saída\n",
    "    if os.path.exists(OUTPUT_DIR):\n",
    "        print(f\"Removendo diretório existente: {OUTPUT_DIR}\")\n",
    "        shutil.rmtree(OUTPUT_DIR)\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    \n",
    "    label_map = get_label_map()\n",
    "    \n",
    "    # A) Coletar dados sintéticos (EnglishFnt)\n",
    "    fnt_files, fnt_labels = collect_all_images(FNT_DIR, label_map)\n",
    "    \n",
    "    # B) Coletar dados naturais (EnglisgImg)\n",
    "    # Ignorando Msk (máscaras) e focando em Bmp (imagens) dos diretórios GoodImg e BadImag\n",
    "    img_files, img_labels = [], []\n",
    "    for quality_dir in ['GoodImg', 'BadImag']:\n",
    "        for type_dir in ['Bmp']: # Focar apenas em Bmp (imagens), ignorar Msk (máscaras)\n",
    "            path = os.path.join(IMG_DIR, quality_dir, type_dir)\n",
    "            files, labels = collect_all_images(path, label_map)\n",
    "            img_files.extend(files)\n",
    "            img_labels.extend(labels)\n",
    "    \n",
    "    # C) Consolidar TODOS os arquivos em uma única lista\n",
    "    all_files = fnt_files + img_files\n",
    "    all_labels = fnt_labels + img_labels\n",
    "    \n",
    "    if not all_files:\n",
    "        print(\"ERRO: Nenhuma imagem encontrada. Verifique os caminhos de diretório.\")\n",
    "    else:\n",
    "        print(f\"\\nTOTAL de imagens coletadas: {len(all_files)}\")\n",
    "        \n",
    "        # 5. DIVISÃO ESTRATIFICADA (Duas Etapas)\n",
    "        \n",
    "        # Passo 1: Treinamento vs. Teste/Validação (80% vs 20%)\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "            all_files, all_labels, \n",
    "            test_size=(VAL_RATIO + TEST_RATIO), \n",
    "            random_state=42, \n",
    "            shuffle=True, \n",
    "            stratify=all_labels\n",
    "        )\n",
    "\n",
    "        # Passo 2: Validação vs. Teste (10% vs 10%)\n",
    "        # Calcula o novo ratio de teste em relação ao conjunto temporário (0.5 = 10% / 20%)\n",
    "        test_size_ratio = TEST_RATIO / (VAL_RATIO + TEST_RATIO) \n",
    "        \n",
    "        X_val, X_test, y_val, y_test = train_test_split(\n",
    "            X_temp, y_temp, \n",
    "            test_size=test_size_ratio, \n",
    "            random_state=42, \n",
    "            shuffle=True, \n",
    "            stratify=y_temp\n",
    "        )\n",
    "        \n",
    "        print(\"\\n--- RESUMO DA DIVISÃO ESTRATIFICADA ---\")\n",
    "        print(f\"Treinamento: {len(X_train)} imagens ({len(X_train)/len(all_files):.1%})\")\n",
    "        print(f\"Validação: {len(X_val)} imagens ({len(X_val)/len(all_files):.1%})\")\n",
    "        print(f\"Teste: {len(X_test)} imagens ({len(X_test)/len(all_files):.1%})\")\n",
    "        print(\"---------------------------------------\")\n",
    "        \n",
    "        # 6. COPIAR ARQUIVOS PARA A ESTRUTURA FINAL\n",
    "        create_and_copy(X_train, y_train, 'train')\n",
    "        create_and_copy(X_val, y_val, 'validation')\n",
    "        create_and_copy(X_test, y_test, 'test')\n",
    "        \n",
    "        print(\"\\n✅ Organização concluída! O dataset final está em 'chars74k_dataset_final'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
