{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abf0c2e8",
   "metadata": {},
   "source": [
    "# Passo a Passo para o Treinamento com Chars74K\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Preparação e Carregamento do Dataset\n",
    "\n",
    "O Chars74K é um dataset mais complexo de carregar do que o MNIST.\n",
    "\n",
    "* **1.1. Download e Organização:** Baixe o conjunto de dados completo. Ele é frequentemente distribuído em pastas separadas para os três domínios (**Natural**, **Synthesized** e **Handwritten**).\n",
    "* **1.2. Definição das Classes (Rótulos):** O dataset contém 62 classes (10 dígitos e 52 letras - maiúsculas e minúsculas).\n",
    "* **1.3. Pré-processamento Inicial:**\n",
    "    * **Redimensionamento:** As imagens naturais têm tamanhos variados. Redimensione todas para um tamanho padrão que sua CNN possa aceitar (ex: $64 \\times 64$ ou $128 \\times 128$ pixels).\n",
    "    * **Normalização:** Converta as imagens para *grayscale* (escala de cinza) para reduzir a complexidade ou mantenha-as coloridas (RGB), dependendo do seu objetivo. Normalize os valores de pixel para o intervalo $[0, 1]$ (dividindo por 255).\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Divisão dos Dados (Treinamento, Validação e Teste)\n",
    "\n",
    "A divisão é crucial para garantir que você avalie o modelo em dados que ele nunca viu.\n",
    "\n",
    "* **2.1. Proporções:** A divisão mais comum e eficiente é:\n",
    "    * **Treinamento:** $70\\%$ a $80\\%$ (usado para ajustar os pesos da CNN).\n",
    "    * **Validação:** $10\\%$ a $15\\%$ (usado para ajustar os hiperparâmetros e decidir quando parar o treinamento).\n",
    "    * **Teste:** $10\\%$ a $15\\%$ (usado apenas no final para uma avaliação imparcial da performance final).\n",
    "* **2.2. Estratificação:** É altamente recomendado realizar a divisão de forma **estratificada**. Isso garante que a distribuição das 62 classes de caracteres seja mantida (proporcional) em cada um dos três subconjuntos.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Arquitetura da CNN e Configuração Inicial\n",
    "\n",
    "* **3.1. Escolha da Arquitetura:** Comece com uma CNN simples (arquitetura *baseline*).\n",
    "    * **Exemplo Básico:** `CONV -> RELU -> POOL -> CONV -> RELU -> POOL -> FLATTEN -> DENSE -> SOFTMAX`.\n",
    "    * **Camadas:** Use 3 a 5 camadas convolucionais seguidas de *pooling*.\n",
    "* **3.2. Hiperparâmetros Iniciais (para o treinamento *baseline*):**\n",
    "    * **Função de Perda:** *Categorical Cross-Entropy* (Pois é um problema de classificação multiclasse).\n",
    "    * **Otimizador:** Adam (Ponto de partida robusto).\n",
    "    * **Taxa de Aprendizagem ($\\alpha$):** $10^{-3}$ ou $10^{-4}$.\n",
    "    * **Tamanho do Lote (*Batch Size*):** 32 ou 64.\n",
    "    * **Épocas:** 10 a 20.\n",
    "* **3.3. Treinamento *Baseline* e Documentação:** Treine o modelo inicial e **documente** a precisão (accuracy) e a perda (*loss*) nos conjuntos de treinamento e validação para estabelecer o ponto de partida.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Evolução na Metodologia e Otimização\n",
    "\n",
    "Esta é a fase onde você melhora o desempenho e atende ao requisito de \"evolução na metodologia\".\n",
    "\n",
    "### A. Aumento de Dados (*Data Augmentation*)\n",
    "\n",
    "O Chars74K é diversificado, mas o aumento de dados melhora a generalização, especialmente com imagens naturais.\n",
    "\n",
    "* **Implementação:** Aplique transformações aleatórias **apenas** no conjunto de **treinamento**:\n",
    "    * Rotação (pequenos ângulos).\n",
    "    * Zoom (leve).\n",
    "    * Deslocamento de Largura/Altura.\n",
    "    * Inclusão de ruído (*noise*).\n",
    "* **Documentação:** Compare os resultados da *baseline* (Sem Augmentation) com a nova rodada (Com Augmentation).\n",
    "\n",
    "### B. Teste de Arquiteturas Diferentes\n",
    "\n",
    "* **CNN Mais Profunda:** Adicione mais camadas convolucionais e *pooling* para capturar características mais complexas.\n",
    "* **Inclusão de *Dropout*:** Adicione camadas de *Dropout* ($20\\%$ a $50\\%$) após as camadas convolucionais e/ou densas para prevenir *overfitting* (um problema comum em conjuntos de dados com alta variabilidade como o Chars74K).\n",
    "\n",
    "### C. Transfer Learning (Metodologia Avançada)\n",
    "\n",
    "Se a precisão ainda estiver baixa, o *Transfer Learning* é a melhor forma de evolução.\n",
    "\n",
    "* **Estratégia:** Utilize os pesos pré-treinados de uma rede grande e robusta (treinada em milhões de imagens, como **ImageNet**), como:\n",
    "    * **VGG16 / VGG19**\n",
    "    * **ResNet**\n",
    "    * **MobileNet**\n",
    "* **Ajuste Fino (*Fine-Tuning*):**\n",
    "    1.  Carregue a arquitetura e os pesos pré-treinados (exclua a camada de saída).\n",
    "    2.  Congele as primeiras camadas.\n",
    "    3.  Adicione suas novas camadas densas (com 62 saídas, uma para cada classe).\n",
    "    4.  Treine apenas as novas camadas.\n",
    "    5.  (Opcional) Descongele as últimas camadas convolucionais do modelo base e treine novamente com uma taxa de aprendizado **muito baixa** ($\\approx 10^{-5}$) para um ajuste fino.\n",
    "\n",
    "### D. Ajuste de Hiperparâmetros\n",
    "\n",
    "Otimize os hiperparâmetros com base nos resultados do conjunto de **validação**:\n",
    "\n",
    "* **Taxa de Aprendizagem:** Use um *Learning Rate Scheduler* para reduzir a taxa durante o treinamento.\n",
    "* **Otimizador:** Teste SGD com *Momentum* ou Adagrad.\n",
    "* **Pesos de Classe:** Se o Chars74K tiver classes desbalanceadas, aplique pesos de classe para penalizar erros nas classes menos representadas.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Avaliação Final\n",
    "\n",
    "* **Avaliação no Conjunto de Teste:** Após selecionar o melhor modelo (o que teve o melhor desempenho no conjunto de **validação**), avalie-o **apenas uma vez** no conjunto de **teste**.\n",
    "* **Métricas:** Apresente a **Matriz de Confusão** e a **Acurácia (Accuracy)** geral do modelo final."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
