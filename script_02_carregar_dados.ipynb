{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "072a45f4",
   "metadata": {},
   "source": [
    "# Script de Carregamento, Pré-processamento e Aumento de Dados\n",
    "\n",
    "O script a seguir utiliza TensorFlow/Keras para carregar as imagens organizadas na pasta chars74k_dataset_final, aplicar o pré-processamento necessário (grayscale, redimensionamento, normalização) e incluir o Aumento de Dados (Data Augmentation) apenas para o conjunto de treinamento.\n",
    "\n",
    "Este é o método ideal para garantir que o modelo CNN receba dados consistentes e robustos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ff8744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 06:16:49.380851: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-20 06:16:57.792451: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-20 06:17:10.495797: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando e pré-processando dados de Treinamento...\n",
      "Found 51804 images belonging to 62 classes.\n",
      "\n",
      "Carregando e pré-processando dados de Validação...\n",
      "Found 7367 images belonging to 62 classes.\n",
      "\n",
      "Carregando e pré-processando dados de Teste...\n",
      "Found 7371 images belonging to 62 classes.\n",
      "\n",
      "--- Informações do Dataset ---\n",
      "Total de classes identificadas: 62\n",
      "Mapeamento de classes (Exemplo): [('0', 0), ('1', 1), ('2', 2), ('3', 3), ('4', 4), ('5', 5), ('6', 6), ('7', 7), ('8', 8), ('9', 9)]...\n",
      "Formato de um lote de Treinamento (X): (32, 64, 64, 1)\n",
      "Formato de um lote de Rótulos (y): (32, 62)\n",
      "Tipo de dados: float32\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# --- 1. CONFIGURAÇÕES GERAIS ---\n",
    "# Caminho para o dataset organizado\n",
    "DATASET_PATH = 'chars74k_dataset_final'\n",
    "\n",
    "# Tamanho alvo para redimensionamento\n",
    "IMAGE_SIZE = (64, 64) \n",
    "\n",
    "# Tamanho do lote (batch) para treinamento\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Número de classes (62 classes: 10 dígitos + 26 maiúsculas + 26 minúsculas)\n",
    "NUM_CLASSES = 62\n",
    "\n",
    "# --- 2. CONFIGURAÇÃO DE AUMENTO DE DADOS (DATA AUGMENTATION) ---\n",
    "\n",
    "# O Data Augmentation deve ser aplicado APENAS ao conjunto de TREINAMENTO\n",
    "train_datagen = ImageDataGenerator(\n",
    "    # Normalização dos pixels para o intervalo [0, 1] (Dividir por 255)\n",
    "    rescale=1./255,\n",
    "    # Técnicas de Augmentation:\n",
    "    rotation_range=10,        # Rotação aleatória (máx. 10 graus)\n",
    "    width_shift_range=0.1,    # Deslocamento horizontal (até 10% da largura)\n",
    "    height_shift_range=0.1,   # Deslocamento vertical (até 10% da altura)\n",
    "    zoom_range=0.1,           # Zoom aleatório\n",
    "    shear_range=0.1,          # Cisalhamento\n",
    "    fill_mode='nearest',      # Estratégia para preencher novos pixels após transformações\n",
    "    # horizontal_flip=True    # Evitado para caracteres, pois 'p' e 'd' podem se confundir\n",
    ")\n",
    "\n",
    "# Para Validação e Teste, fazemos APENAS a Normalização (rescale)\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# --- 3. CARREGAMENTO E PRÉ-PROCESSAMENTO DOS DADOS ---\n",
    "\n",
    "print(\"Carregando e pré-processando dados de Treinamento...\")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(DATASET_PATH, 'train'),\n",
    "    target_size=IMAGE_SIZE,\n",
    "    color_mode='grayscale',           # CONVERTE IMAGENS PARA ESCALA DE CINZA\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',         # Necessário para 62 classes (one-hot encoding)\n",
    "    save_format='png'                 # Mantém o formato PNG (apenas durante o carregamento)\n",
    ")\n",
    "\n",
    "print(\"\\nCarregando e pré-processando dados de Validação...\")\n",
    "validation_generator = val_test_datagen.flow_from_directory(\n",
    "    os.path.join(DATASET_PATH, 'validation'),\n",
    "    target_size=IMAGE_SIZE,\n",
    "    color_mode='grayscale',           # CONVERTE IMAGENS PARA ESCALA DE CINZA\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "print(\"\\nCarregando e pré-processando dados de Teste...\")\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    os.path.join(DATASET_PATH, 'test'),\n",
    "    target_size=IMAGE_SIZE,\n",
    "    color_mode='grayscale',           # CONVERTE IMAGENS PARA ESCALA DE CINZA\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False                     # Desativa o shuffle para manter a ordem para avaliação final\n",
    ")\n",
    "\n",
    "# --- 4. VERIFICAÇÃO E INFORMAÇÕES ADICIONAIS ---\n",
    "\n",
    "print(\"\\n--- Informações do Dataset ---\")\n",
    "print(f\"Total de classes identificadas: {len(train_generator.class_indices)}\")\n",
    "print(f\"Mapeamento de classes (Exemplo): {list(train_generator.class_indices.items())[:10]}...\") \n",
    "\n",
    "# Exemplo de como um batch de dados aparece\n",
    "X, y = next(train_generator)\n",
    "print(f\"Formato de um lote de Treinamento (X): {X.shape}\") # Deve ser (BATCH_SIZE, 64, 64, 1)\n",
    "print(f\"Formato de um lote de Rótulos (y): {y.shape}\")     # Deve ser (BATCH_SIZE, NUM_CLASSES)\n",
    "print(f\"Tipo de dados: {X.dtype}\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Onde `train_generator`, `validation_generator` e `test_generator` \n",
    "# estão prontos para serem passados para o método model.fit().\n",
    "# ----------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
